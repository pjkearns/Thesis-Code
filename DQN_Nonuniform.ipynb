{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mr0grvgEIIH"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from FH_Functions import opt_fracs, get_truncated_normal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network is very similar to uniform network, only differences in environment and dqn func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "ujF51HlOETVp"
   },
   "outputs": [],
   "source": [
    "#@title Qnet\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=16, fc2_units=16):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b-cy1kfhqONW",
    "outputId": "c91bd5ee-51bd-4efa-9df8-cc330c604c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 1.00            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 1e-3               # learning rate \n",
    "UPDATE_EVERY = 10       # how often to update the network\n",
    "\n",
    "\"\"\"GPU only faster for larger networks\"\"\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "-HXpQNEzEUoh"
   },
   "outputs": [],
   "source": [
    "#@title Agent, Replay\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "3R5QJjA2zNoc"
   },
   "outputs": [],
   "source": [
    "#@title NON-UNIFORM Environment\n",
    "class DQNNonUniformLineSearchEnv():\n",
    "    def __init__(self, lam = 0.4, Nsamples = 5, Nstates = 501):\n",
    "         \n",
    "        self.lam      = lam\n",
    "        self.Nactions = 101\n",
    "        self.Nsamples = Nsamples\n",
    "        self.S        = np.linspace(0,1,Nstates)\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action, theta):  # return the next state \n",
    "        done = False\n",
    "        thtMin = self.thtMin\n",
    "        thtMax = self.thtMax\n",
    "        Xc = self.Xc\n",
    "        Xo = self.Xo \n",
    "        N = self.state[1]\n",
    "        \n",
    "        size   = thtMax - thtMin        \n",
    "        act    = 0.5 * (action / (self.Nactions-1))\n",
    "        dist   = size * act\n",
    "        dist   = self.S[np.argmin(np.abs(self.S - dist))]\n",
    "\n",
    "        if Xc < theta:\n",
    "            Xc = Xc + dist\n",
    "        else:\n",
    "            Xc = Xc - dist\n",
    "            \n",
    "        Xc = self.S[np.argmin(np.abs(self.S - Xc))]\n",
    "        \n",
    "        if Xc < theta:\n",
    "            thtMin = Xc\n",
    "            Xo = thtMax\n",
    "        else:\n",
    "            thtMax = Xc\n",
    "            Xo = thtMin\n",
    "            \n",
    "        newSize = thtMax - thtMin\n",
    "            \n",
    "        reward = size - newSize - self.lam*dist\n",
    "        \n",
    "        self.thtMin = thtMin\n",
    "        self.thtMax = thtMax\n",
    "        self.Xc     = Xc\n",
    "        self.Xo     = Xo\n",
    "        self.state  = np.array([self.lam, N-1, self.Xc, self.Xo])\n",
    "        \n",
    "        if self.state[1] == 0:\n",
    "            done = True\n",
    "        return self.state, reward, done\n",
    "    \n",
    "    def reset(self):       \n",
    "        self.thtMin = 0\n",
    "        self.thtMax = 1\n",
    "        self.Xc     = 0\n",
    "        self.Xo     = 1\n",
    "        self.state  = np.array([self.lam, self.Nsamples, self.Xc, self.Xo])\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "R6AFL0QYEYFb"
   },
   "outputs": [],
   "source": [
    "#@title DQN\n",
    "def dqn(agent, env, n_episodes=2000, eps_start=1.0, eps_end=0.1, eps_decay=0.9999):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        target_scores (float): average scores aming to achieve, the agent will stop training once it reaches this scores\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    thtDist = get_truncated_normal(0.5, 0.1, 0, 1)\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        # Reset env and score at the beginning of episode\n",
    "        thtRange = thtDist.rvs(100)           # draw 100 thetas from the distribution\n",
    "        \n",
    "        for tht in thtRange:\n",
    "            state = env.reset()               # get the current state\n",
    "            score = 0                         # initialize the score\n",
    "            done  = False\n",
    "\n",
    "            while not done:\n",
    "                action = agent.act(state, eps)            \n",
    "                next_state, reward, done = env.step(action, tht)            \n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break \n",
    "            scores_window.append(score)       # save most recent score\n",
    "            scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tEps: {:.4f}'.format(i_episode, np.mean(scores_window), eps), end=\"\")\n",
    "        \n",
    "        if i_episode % 1000 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tEps: {:.4f}'.format(i_episode, np.mean(scores_window), eps))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8PkMPMOEZeD"
   },
   "outputs": [],
   "source": [
    "Nsteps = 5\n",
    "env   = DQNNonUniformLineSearchEnv(Nsamples = Nsteps)\n",
    "agent = Agent(state_size=4, action_size=101, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "4ruzOu6lLqoJ",
    "outputId": "0b7b1880-9c4a-4c28-be6f-f36e2459580a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5\tAverage Score: 0.6266\tEps: 0.9975\n",
      "time: 1.61\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "scores = dqn(agent, env, n_episodes=5, eps_decay = 0.9995)\n",
    "stop = time.time()\n",
    "print(\"\\ntime: %.2f\"%(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.qnetwork_local.state_dict(), './Policies/DQN_Nonuniform_ReLU.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load in pre-saved agent if not re-training\"\"\"\n",
    "agent = Agent(state_size=4, action_size=101, seed=0)\n",
    "agent.qnetwork_local.to(device)\n",
    "agent.qnetwork_local.load_state_dict(torch.load('./Policies/DQN_Nonuniform_ReLU.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "5LAqx6p0E1j9",
    "outputId": "b7262554-dc94-423f-b044-aeb180f949e9"
   },
   "outputs": [],
   "source": [
    "lam = 0.4\n",
    "states = np.arange(1,Nsteps + 1)\n",
    "DQNacts = np.zeros(Nsteps)\n",
    "cost = 0\n",
    "\n",
    "thtDist = get_truncated_normal(0.5, 0.1, 0, 1)\n",
    "np.random.seed(0)\n",
    "thtRange = thtDist.rvs(1000)\n",
    "\n",
    "S = np.linspace(0,1,501)\n",
    "\n",
    "for theta in thtRange:\n",
    "    Xc = 0\n",
    "    Xo = 1\n",
    "    lb = 0\n",
    "    ub = 1\n",
    "    totDist = 0\n",
    "    for ii in states[::-1]:\n",
    "        length = ub - lb\n",
    "        stt = np.array([lam, ii, Xc, Xo])\n",
    "        action = agent.act(stt, 0)\n",
    "        action = 0.5*action/101\n",
    "        DQNacts[-ii] += action\n",
    "\n",
    "        dist = length*action\n",
    "        dist = S[np.argmin(np.abs(S - dist))]\n",
    "        totDist += dist\n",
    "        \n",
    "        if Xc < theta:   \n",
    "            Xc += dist\n",
    "\n",
    "        else:\n",
    "            Xc -= dist\n",
    "            \n",
    "        Xc = S[np.argmin(np.abs(S - Xc))]\n",
    "\n",
    "        if Xc < theta:\n",
    "            lb = Xc\n",
    "            Xo = ub\n",
    "        else:\n",
    "            ub = Xc\n",
    "            Xo = lb\n",
    "\n",
    "    cost += lam*totDist + (ub - lb)\n",
    "    \n",
    "DQNacts /= 1000\n",
    "cost /= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "5LAqx6p0E1j9",
    "outputId": "b7262554-dc94-423f-b044-aeb180f949e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions:  [0.34653465 0.15007921 0.18039604 0.25220792 0.29666832]\n",
      "Average cost:  0.27586959999999994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(states,DQNacts)\n",
    "print(\"Actions: \", DQNacts)\n",
    "print(\"Average cost: \", cost)   \n",
    "# np.save('./DQN_bestAction_mu5_sig1_lam4_N5_s501_A101',DQNacts)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DQN_nonuniform.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
